{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torch.distributions as D\n",
    "from diffusers.models.autoencoders.autoencoder_kl import AutoencoderKL\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"dark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda:1\")\n",
    "    # if torch.backends.mps.is_available():\n",
    "        # return torch.device(\"mps\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "DEVICE = get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast\n",
    "\n",
    "vae = AutoencoderKL.from_pretrained(\"stabilityai/sdxl-vae\").to(DEVICE)\n",
    "# vae = cast(AutoencoderKL, torch.compile(vae, mode=\"max-autotune\"))\n",
    "vae.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomRotation(10),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, train: bool = True):\n",
    "        self.cifar = torchvision.datasets.CIFAR10(root=\"/tmp/cifar\", download=True, train=train, transform=transform)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cifar)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        x, y = self.cifar[idx]\n",
    "        t = torch.rand(1)\n",
    "        return x, y, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 3, 32, 32]),\n",
       " torch.Size([256]),\n",
       " torch.Size([256, 1]),\n",
       " torch.Size([4, 4, 4]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_train = CifarDataset(train=True)\n",
    "cifar_test = CifarDataset(train=False)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(cifar_train, batch_size=256, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(cifar_test, batch_size=256, shuffle=True)\n",
    "\n",
    "latent_shape = vae.encode(next(iter(train_dataloader))[0].to(DEVICE), return_dict=False)[0].mean[0].shape\n",
    "\n",
    "next(iter(train_dataloader))[0].shape, next(iter(train_dataloader))[1].shape, next(iter(train_dataloader))[2].shape, latent_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "    def forward(self, x):\n",
    "        half_dim = self.dim // 2\n",
    "        emb = torch.exp(-torch.arange(half_dim, device=x.device) * torch.log(torch.tensor(10000.0)) / (half_dim - 1))\n",
    "        emb = x.unsqueeze(1) * emb.unsqueeze(0)\n",
    "        return torch.cat([emb.sin(), emb.cos()], dim=-1)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, time_emb_dim, groups=8):\n",
    "        super().__init__()\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_emb_dim, out_ch)\n",
    "        )\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.GroupNorm(groups, in_ch),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.GroupNorm(groups, out_ch),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "        )\n",
    "        self.res_conv = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
    "\n",
    "    def forward(self, x, t_emb):\n",
    "        h = self.conv_block(x)\n",
    "        time_proj = self.time_mlp(t_emb).unsqueeze(-1).unsqueeze(-1)\n",
    "        h = h + time_proj\n",
    "        return h + self.res_conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_ch=4, base_ch=64, channel_mults=(1, 2), time_emb_dim=128):\n",
    "        super().__init__()\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalPosEmb(time_emb_dim),\n",
    "            nn.Linear(time_emb_dim, time_emb_dim * 4),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_emb_dim * 4, time_emb_dim),\n",
    "        )\n",
    "        self.init_conv = nn.Conv2d(in_ch, base_ch, 3, padding=1)\n",
    "        down_chs = [base_ch * m for m in channel_mults]\n",
    "        self.downs = nn.ModuleList()\n",
    "        prev_ch = base_ch\n",
    "        for ch in down_chs:\n",
    "            self.downs.append(ResidualBlock(prev_ch, ch, time_emb_dim))\n",
    "            prev_ch = ch\n",
    "        self.bottleneck = ResidualBlock(prev_ch, prev_ch, time_emb_dim)\n",
    "        self.ups = nn.ModuleList()\n",
    "        for idx, ch in enumerate(reversed(down_chs)):\n",
    "            # ch is skip channel\n",
    "            out_ch = down_chs[-2 - idx] if idx < len(down_chs) - 1 else base_ch\n",
    "            self.ups.append(nn.ModuleDict({\n",
    "                'upsample': nn.ConvTranspose2d(prev_ch, out_ch, 4, 2, 1),\n",
    "                'res': ResidualBlock(out_ch + ch, out_ch, time_emb_dim)\n",
    "            }))\n",
    "            prev_ch = out_ch\n",
    "        self.final_conv = nn.Sequential(\n",
    "            nn.GroupNorm(8, base_ch),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(base_ch, in_ch, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # x: (B, C, H, W), t: (B,)\n",
    "        t_emb = self.time_mlp(t)\n",
    "        h = self.init_conv(x)\n",
    "        skips = []\n",
    "        for block in self.downs:\n",
    "            h = block(h, t_emb)\n",
    "            skips.append(h)\n",
    "            h = F.avg_pool2d(h, 2)\n",
    "        h = self.bottleneck(h, t_emb)\n",
    "        for module in self.ups:\n",
    "            module = cast(nn.ModuleDict, module)\n",
    "            h = module['upsample'](h)\n",
    "            skip = skips.pop()\n",
    "            h = torch.cat([h, skip], dim=1)\n",
    "            h = module['res'](h, t_emb)\n",
    "        # final\n",
    "        return self.final_conv(h)\n",
    "\n",
    "    def ode_forward(self, t: torch.Tensor, x: torch.Tensor):\n",
    "        t_tensor = t.repeat(x.shape[0])\n",
    "        return self.forward(x, t_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 200\n",
    "\n",
    "ckpt_path = \"../ckpt/UNet\"\n",
    "\n",
    "model = UNet()\n",
    "model = model.to(DEVICE)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=N_EPOCHS)\n",
    "\n",
    "if ckpt_path and False:\n",
    "    model.load_state_dict(torch.load(f\"{ckpt_path}/model.pth\", map_location=DEVICE))\n",
    "    optimizer.load_state_dict(torch.load(f\"{ckpt_path}/optimizer.pth\", map_location=DEVICE))\n",
    "    scheduler.load_state_dict(torch.load(f\"{ckpt_path}/scheduler.pth\", map_location=DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdiffeq import odeint\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample_with_ode(\n",
    "    model: nn.Module,\n",
    "    n_samples: int = 500,\n",
    "    n_steps: int = 25,\n",
    "):\n",
    "    model.eval()\n",
    "    model_device = next(model.parameters()).device\n",
    "    initial_samples = torch.randn((n_samples, *latent_shape), device=model_device)\n",
    "    t_span = torch.linspace(0.0, 1.0, n_steps).to(model_device)\n",
    "    trajectory = odeint(\n",
    "        model.ode_forward,\n",
    "        initial_samples,\n",
    "        t_span,\n",
    "        method=\"euler\",\n",
    "        atol=1e-5,\n",
    "        rtol=1e-5,\n",
    "    )\n",
    "    trajectory = cast(torch.Tensor, trajectory)\n",
    "\n",
    "    return trajectory[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "import os\n",
    "\n",
    "def to_latent(vae: AutoencoderKL, x_raw: torch.Tensor) -> torch.Tensor:\n",
    "    return vae.encode(x_raw, return_dict=False)[0].mean\n",
    "\n",
    "\n",
    "def from_latent(vae: AutoencoderKL, z: torch.Tensor) -> torch.Tensor:\n",
    "    return vae.decode(cast(torch.FloatTensor, z), return_dict=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    val_dataloader: DataLoader,\n",
    "    n_epochs: int,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    scheduler: torch.optim.lr_scheduler.CosineAnnealingLR,\n",
    "    verbose: bool = False,\n",
    "    contrastive_flow_weight: float = 0.05,\n",
    "):\n",
    "    def step(x_raw, t):\n",
    "        x = to_latent(vae, x_raw)\n",
    "        noise = torch.randn_like(x, device=DEVICE)\n",
    "        t_expanded = t.unsqueeze(-1).unsqueeze(-1)\n",
    "        z = t_expanded * x + (1 - t_expanded) * noise\n",
    "        target_u = x - noise\n",
    "        u = model(z, t.squeeze(-1))\n",
    "        loss = F.mse_loss(u, target_u)\n",
    "        if contrastive_flow_weight > 0.0:\n",
    "            u_hat = torch.roll(u, shifts=1, dims=0)\n",
    "            loss_contrastive = F.mse_loss(u, u_hat)\n",
    "            loss = loss - contrastive_flow_weight * loss_contrastive\n",
    "        return loss\n",
    "\n",
    "    def get_fid(nfe: int = 25):\n",
    "        real_images = next(iter(val_dataloader))[0]\n",
    "        real_images = (real_images * 255).to(torch.uint8).to(DEVICE) # BS x 3 x 32 x 32\n",
    "        z_s = sample_with_ode(model, n_samples=real_images.shape[0], n_steps=nfe)\n",
    "        generated_images = from_latent(vae, z_s)\n",
    "        generated_images = (generated_images * 255).to(torch.uint8).to(DEVICE) # BS x 3 x 32 x 32\n",
    "        fid = FrechetInceptionDistance().to(DEVICE)\n",
    "        fid.update(real_images, real=True)\n",
    "        fid.update(generated_images, real=False)\n",
    "        return fid.compute()\n",
    "\n",
    "    def ckpt_callback(epoch: int, val_loss: float):\n",
    "        ckpt_dir = \"../ckpt\"\n",
    "        subdir = f\"{ckpt_dir}/{model.__class__.__name__}\"\n",
    "        if not os.path.exists(subdir):\n",
    "            os.makedirs(subdir)\n",
    "        torch.save(model.state_dict(), f\"{subdir}/model.pth\")\n",
    "        torch.save(optimizer.state_dict(), f\"{subdir}/optimizer.pth\")\n",
    "        torch.save(scheduler.state_dict(), f\"{subdir}/scheduler.pth\")\n",
    "        print(f\"Saved checkpoint at epoch {epoch} with val loss {val_loss:.4f}\")\n",
    "\n",
    "    log_interval = 1\n",
    "    model.train()\n",
    "    best_val_loss = float(\"inf\")\n",
    "    loss_history = []\n",
    "    val_loss_history = []\n",
    "    fid_25_history = []\n",
    "    fid_50_history = []\n",
    "    for epoch in range(n_epochs):\n",
    "        losses = []\n",
    "        for x_raw,_, t in dataloader:\n",
    "            loss = step(x_raw.to(DEVICE), t.to(DEVICE))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for x_raw,_, t in val_dataloader:\n",
    "                loss = step(x_raw.to(DEVICE), t.to(DEVICE))\n",
    "                val_losses.append(loss.item())\n",
    "\n",
    "        current_loss = float(np.mean(losses))\n",
    "        current_val_loss = float(np.mean(val_losses))\n",
    "\n",
    "        fid_25 = get_fid(nfe=25)\n",
    "        fid_50 = get_fid(nfe=50)\n",
    "        fid_25_history.append(fid_25)\n",
    "        fid_50_history.append(fid_50)\n",
    "        if (epoch % log_interval == 0 or epoch == n_epochs - 1) and verbose:\n",
    "            print(f\"Epoch {epoch}\\t loss: {current_loss:.4f}\\t val loss: {current_val_loss:.4f}\\t FID_25: {fid_25:.4f}\\t FID_50: {fid_50:.4f}\")\n",
    "\n",
    "        loss_history.append(current_loss)\n",
    "        val_loss_history.append(current_val_loss)\n",
    "\n",
    "        if current_val_loss < best_val_loss:\n",
    "            best_val_loss = current_val_loss\n",
    "            ckpt_callback(epoch, current_val_loss)\n",
    "\n",
    "    return loss_history, val_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\t loss: 19.9613\t val loss: 16.8138\t FID_25: 275.2579\t FID_50: 282.5410\n",
      "Saved checkpoint at epoch 0 with val loss 16.8138\n",
      "Epoch 1\t loss: 14.9413\t val loss: 13.6745\t FID_25: 267.5249\t FID_50: 271.3111\n",
      "Saved checkpoint at epoch 1 with val loss 13.6745\n",
      "Epoch 2\t loss: 12.2915\t val loss: 11.4090\t FID_25: 266.2974\t FID_50: 264.9057\n",
      "Saved checkpoint at epoch 2 with val loss 11.4090\n"
     ]
    }
   ],
   "source": [
    "loss_history, val_loss_history = train(\n",
    "    model=model,\n",
    "    dataloader=train_dataloader,\n",
    "    val_dataloader=test_dataloader,\n",
    "    n_epochs=N_EPOCHS,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    verbose=True,\n",
    ")\n",
    "plt.plot(loss_history)\n",
    "plt.plot(val_loss_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_rectified_dataset(\n",
    "    model_v0: nn.Module, original_dataset: torch.Tensor, n_steps=100, batch_size=512\n",
    "):\n",
    "    model_v0.eval()\n",
    "    model_device = next(model_v0.parameters()).device\n",
    "    t_span = torch.linspace(1.0, 0.0, n_steps).to(model_device)\n",
    "    p1_data = original_dataset.to(model_device)\n",
    "\n",
    "    p0_rectified_list = []\n",
    "    for p1_batch in torch.split(p1_data, batch_size):\n",
    "        p0_batch = odeint(\n",
    "            model_v0.ode_forward,\n",
    "            p1_batch,\n",
    "            t_span,\n",
    "            method=\"euler\",\n",
    "            atol=1e-5,\n",
    "            rtol=1e-5,\n",
    "        )[-1]\n",
    "        p0_rectified_list.append(p0_batch)\n",
    "\n",
    "    p0_rectified = torch.cat(p0_rectified_list, dim=0)\n",
    "    return TensorDataset(p0_rectified.cpu(), original_dataset.cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS_RF = 100\n",
    "rf_model = Flow().to(DEVICE)\n",
    "rectified_dataset = generate_rectified_dataset(model_v0=model.to(\"cpu\"), original_dataset=data.X)\n",
    "dataloader = DataLoader(rectified_dataset, batch_size=128, shuffle=True)\n",
    "optimizer = AdamW(rf_model.parameters(), lr=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=N_EPOCHS_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = train(\n",
    "    rf_model,\n",
    "    dataloader,\n",
    "    n_epochs=N_EPOCHS_RF,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    t_dist=time_distribution,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_plot(rf_model, title=\"Contrastive Flow\", n_samples=1000, n_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_plot(rf_model, title=\"Contrastive Flow\", n_samples=1000, n_steps=20, animate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_2 = Flow().to(DEVICE)\n",
    "rectified_dataset = generate_rectified_dataset(\n",
    "    model_v0=rf_model, original_dataset=data.X\n",
    ")\n",
    "dataloader = DataLoader(rectified_dataset, batch_size=128, shuffle=True)\n",
    "optimizer = AdamW(rf_model_2.parameters(), lr=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=N_EPOCHS_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = train(\n",
    "    rf_model_2,\n",
    "    dataloader,\n",
    "    n_epochs=N_EPOCHS_RF,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    t_dist=time_distribution,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_plot(rf_model_2, title=\"Contrastive Flow (Reflow #2)\", n_samples=1000, n_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_plot(rf_model_2, title=\"Contrastive Flow (Reflow #2)\", n_samples=1000, n_steps=5, animate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
