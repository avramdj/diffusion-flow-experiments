{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, LinearLR\n",
    "import torch.distributions as D\n",
    "from diffusers.models.autoencoders.autoencoder_kl import AutoencoderKL\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"dark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    # if torch.backends.mps.is_available():\n",
    "    # return torch.device(\"mps\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "DEVICE = get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast\n",
    "\n",
    "vae = AutoencoderKL.from_pretrained(\"stabilityai/sdxl-vae\").to(DEVICE)\n",
    "# vae = cast(AutoencoderKL, torch.compile(vae, mode=\"max-autotune\"))\n",
    "vae.eval()\n",
    "if DEVICE == torch.device(\"cuda\"):\n",
    "    vae = cast(AutoencoderKL, torch.compile(vae, mode=\"max-autotune\"))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.RandomCrop(32, padding=4),\n",
    "        torchvision.transforms.RandomRotation(10),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, train: bool = True):\n",
    "        self.cifar = torchvision.datasets.CIFAR10(\n",
    "            root=\"/tmp/cifar\", download=True, train=train, transform=transform\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cifar)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        x, y = self.cifar[idx]\n",
    "        t = torch.rand(1)\n",
    "        return x, y, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 3, 32, 32]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512, 1]),\n",
       " torch.Size([4, 4, 4]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_train = CifarDataset(train=True)\n",
    "cifar_test = CifarDataset(train=False)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    cifar_train, batch_size=512, shuffle=True\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(cifar_test, batch_size=512, shuffle=True)\n",
    "\n",
    "latent_shape = (\n",
    "    vae.encode(next(iter(train_dataloader))[0].to(DEVICE), return_dict=False)[0]\n",
    "    .mean[0]\n",
    "    .shape\n",
    ")\n",
    "\n",
    "(\n",
    "    next(iter(train_dataloader))[0].shape,\n",
    "    next(iter(train_dataloader))[1].shape,\n",
    "    next(iter(train_dataloader))[2].shape,\n",
    "    latent_shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        half_dim = self.dim // 2\n",
    "        emb = torch.exp(\n",
    "            -torch.arange(half_dim, device=x.device)\n",
    "            * torch.log(torch.tensor(10000.0))\n",
    "            / (half_dim - 1)\n",
    "        )\n",
    "        emb = x.unsqueeze(1) * emb.unsqueeze(0)\n",
    "        return torch.cat([emb.sin(), emb.cos()], dim=-1)\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, time_emb_dim, groups=8):\n",
    "        super().__init__()\n",
    "        self.time_mlp = nn.Sequential(nn.SiLU(), nn.Linear(time_emb_dim, out_ch))\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.GroupNorm(groups, in_ch),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.GroupNorm(groups, out_ch),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "        )\n",
    "        self.res_conv = (\n",
    "            nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t_emb):\n",
    "        h = self.conv_block(x)\n",
    "        time_proj = self.time_mlp(t_emb).unsqueeze(-1).unsqueeze(-1)\n",
    "        h = h + time_proj\n",
    "        return h + self.res_conv(x)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_ch=4, base_ch=64, channel_mults=(1, 2), time_emb_dim=128):\n",
    "        super().__init__()\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalPosEmb(time_emb_dim),\n",
    "            nn.Linear(time_emb_dim, time_emb_dim * 4),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_emb_dim * 4, time_emb_dim),\n",
    "        )\n",
    "        self.init_conv = nn.Conv2d(in_ch, base_ch, 3, padding=1)\n",
    "        down_chs = [base_ch * m for m in channel_mults]\n",
    "        self.downs = nn.ModuleList()\n",
    "        prev_ch = base_ch\n",
    "        for ch in down_chs:\n",
    "            self.downs.append(ResidualBlock(prev_ch, ch, time_emb_dim))\n",
    "            prev_ch = ch\n",
    "        self.bottleneck = ResidualBlock(prev_ch, prev_ch, time_emb_dim)\n",
    "        self.ups = nn.ModuleList()\n",
    "        for idx, ch in enumerate(reversed(down_chs)):\n",
    "            # ch is skip channel\n",
    "            out_ch = down_chs[-2 - idx] if idx < len(down_chs) - 1 else base_ch\n",
    "            self.ups.append(\n",
    "                nn.ModuleDict(\n",
    "                    {\n",
    "                        \"upsample\": nn.ConvTranspose2d(prev_ch, out_ch, 4, 2, 1),\n",
    "                        \"res\": ResidualBlock(out_ch + ch, out_ch, time_emb_dim),\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "            prev_ch = out_ch\n",
    "        self.final_conv = nn.Sequential(\n",
    "            nn.GroupNorm(8, base_ch),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(base_ch, in_ch, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # x: (B, C, H, W), t: (B,)\n",
    "        t_emb = self.time_mlp(t)\n",
    "        h = self.init_conv(x)\n",
    "        skips = []\n",
    "        for block in self.downs:\n",
    "            h = block(h, t_emb)\n",
    "            skips.append(h)\n",
    "            h = F.avg_pool2d(h, 2)\n",
    "        h = self.bottleneck(h, t_emb)\n",
    "        for module in self.ups:\n",
    "            module = cast(nn.ModuleDict, module)\n",
    "            h = module[\"upsample\"](h)\n",
    "            skip = skips.pop()\n",
    "            h = torch.cat([h, skip], dim=1)\n",
    "            h = module[\"res\"](h, t_emb)\n",
    "        # final\n",
    "        return self.final_conv(h)\n",
    "\n",
    "    def ode_forward(self, t: torch.Tensor, x: torch.Tensor):\n",
    "        t_tensor = t.repeat(x.shape[0])\n",
    "        return self.forward(x, t_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 200\n",
    "\n",
    "\n",
    "model = UNet()\n",
    "model = model.to(DEVICE)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=N_EPOCHS)\n",
    "\n",
    "ckpt_path = f\"../ckpt/{model.__class__.__name__}\"\n",
    "if ckpt_path and False:\n",
    "    model.load_state_dict(torch.load(f\"{ckpt_path}/model.pth\", map_location=DEVICE))\n",
    "    optimizer.load_state_dict(\n",
    "        torch.load(f\"{ckpt_path}/optimizer.pth\", map_location=DEVICE)\n",
    "    )\n",
    "    scheduler.load_state_dict(\n",
    "        torch.load(f\"{ckpt_path}/scheduler.pth\", map_location=DEVICE)\n",
    "    )\n",
    "\n",
    "if DEVICE == torch.device(\"cuda\"):\n",
    "    model = cast(UNet, torch.compile(model, mode=\"reduce-overhead\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdiffeq import odeint\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample_with_ode(\n",
    "    model: nn.Module,\n",
    "    n_samples: int = 500,\n",
    "    n_steps: int = 25,\n",
    "):\n",
    "    model.eval()\n",
    "    model_device = next(model.parameters()).device\n",
    "    initial_samples = torch.randn((n_samples, *latent_shape), device=model_device)\n",
    "    t_span = torch.linspace(0.0, 1.0, n_steps).to(model_device)\n",
    "    trajectory = odeint(\n",
    "        model.ode_forward,\n",
    "        initial_samples,\n",
    "        t_span,\n",
    "        method=\"euler\",\n",
    "        atol=1e-5,\n",
    "        rtol=1e-5,\n",
    "    )\n",
    "    trajectory = cast(torch.Tensor, trajectory)\n",
    "\n",
    "    return trajectory[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "import os\n",
    "\n",
    "\n",
    "def to_latent(vae: AutoencoderKL, x_raw: torch.Tensor) -> torch.Tensor:\n",
    "    return vae.encode(x_raw, return_dict=False)[0].mean\n",
    "\n",
    "\n",
    "def from_latent(vae: AutoencoderKL, z: torch.Tensor) -> torch.Tensor:\n",
    "    return vae.decode(cast(torch.FloatTensor, z), return_dict=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    val_dataloader: DataLoader,\n",
    "    n_epochs: int,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    scheduler: torch.optim.lr_scheduler.CosineAnnealingLR,\n",
    "    verbose: bool = False,\n",
    "    contrastive_flow_weight: float = 0.00,\n",
    "):\n",
    "    def step(x_raw, t):\n",
    "        x = to_latent(vae, x_raw)\n",
    "        noise = torch.randn_like(x, device=DEVICE)\n",
    "        t_expanded = t.unsqueeze(-1).unsqueeze(-1)\n",
    "        z = t_expanded * x + (1 - t_expanded) * noise\n",
    "        target_u = x - noise\n",
    "        u = model(z, t.squeeze(-1))\n",
    "        loss = F.mse_loss(u, target_u)\n",
    "        if contrastive_flow_weight > 0.0:\n",
    "            u_hat = torch.roll(u, shifts=1, dims=0)\n",
    "            loss_contrastive = F.mse_loss(u, u_hat)\n",
    "            loss = loss - contrastive_flow_weight * loss_contrastive\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_fid(nfe: int = 25):\n",
    "        real_images = next(iter(val_dataloader))[0]\n",
    "        real_images = (real_images * 255).to(torch.uint8).to(DEVICE)  # BS x 3 x 32 x 32\n",
    "        z_s = sample_with_ode(model, n_samples=real_images.shape[0], n_steps=nfe)\n",
    "        generated_images = from_latent(vae, z_s)\n",
    "        generated_images = (\n",
    "            (generated_images * 255).to(torch.uint8).to(DEVICE)\n",
    "        )  # BS x 3 x 32 x 32\n",
    "        fid = FrechetInceptionDistance().to(DEVICE)\n",
    "        fid.update(real_images, real=True)\n",
    "        fid.update(generated_images, real=False)\n",
    "        return fid.compute()\n",
    "\n",
    "    def ckpt_callback(epoch: int, val_loss: float):\n",
    "        ckpt_dir = \"../ckpt\"\n",
    "        subdir = f\"{ckpt_dir}/{model.__class__.__name__}\"\n",
    "        if not os.path.exists(subdir):\n",
    "            os.makedirs(subdir)\n",
    "        torch.save(model.state_dict(), f\"{subdir}/model.pth\")\n",
    "        torch.save(optimizer.state_dict(), f\"{subdir}/optimizer.pth\")\n",
    "        torch.save(scheduler.state_dict(), f\"{subdir}/scheduler.pth\")\n",
    "        print(f\"Saved checkpoint at epoch {epoch} with val loss {val_loss:.4f}\")\n",
    "\n",
    "    log_interval = 1\n",
    "    model.train()\n",
    "    best_val_loss = float(\"inf\")\n",
    "    loss_history = []\n",
    "    val_loss_history = []\n",
    "    fid_25_history = []\n",
    "    fid_50_history = []\n",
    "    for epoch in range(n_epochs):\n",
    "        losses = []\n",
    "        for x_raw, _, t in tqdm(dataloader):\n",
    "            loss = step(x_raw.to(DEVICE), t.to(DEVICE))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for x_raw, _, t in val_dataloader:\n",
    "                loss = step(x_raw.to(DEVICE), t.to(DEVICE))\n",
    "                val_losses.append(loss.item())\n",
    "\n",
    "        current_loss = float(np.mean(losses))\n",
    "        current_val_loss = float(np.mean(val_losses))\n",
    "\n",
    "        fid_25 = get_fid(nfe=25)\n",
    "        fid_50 = get_fid(nfe=50)\n",
    "        fid_25_history.append(fid_25)\n",
    "        fid_50_history.append(fid_50)\n",
    "        if (epoch % log_interval == 0 or epoch == n_epochs - 1) and verbose:\n",
    "            print(\n",
    "                f\"Epoch {epoch}\\t loss: {current_loss:.4f}\\t val loss: {current_val_loss:.4f}\\t FID_25: {fid_25:.4f}\\t FID_50: {fid_50:.4f}\"\n",
    "            )\n",
    "\n",
    "        loss_history.append(current_loss)\n",
    "        val_loss_history.append(current_val_loss)\n",
    "\n",
    "        if current_val_loss < best_val_loss:\n",
    "            best_val_loss = current_val_loss\n",
    "            ckpt_callback(epoch, current_val_loss)\n",
    "\n",
    "    return loss_history, val_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ea2dfa40d148609141d1e9bce25509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\t loss: 22.3724\t val loss: 20.1046\t FID_25: 263.0175\t FID_50: 257.9994\n",
      "Saved checkpoint at epoch 0 with val loss 20.1046\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0805d77c33a3440fa25a6bb41ab6cbc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\t loss: 18.4770\t val loss: 17.3702\t FID_25: 249.6280\t FID_50: 250.5529\n",
      "Saved checkpoint at epoch 1 with val loss 17.3702\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9c7eb8a6e6a4676a8fd24c6f50e3c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\t loss: 16.3204\t val loss: 15.7189\t FID_25: 244.5102\t FID_50: 247.2575\n",
      "Saved checkpoint at epoch 2 with val loss 15.7189\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cfe0c1aad7245d8b492355c7acb054c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\t loss: 14.7098\t val loss: 14.1502\t FID_25: 240.9409\t FID_50: 241.9839\n",
      "Saved checkpoint at epoch 3 with val loss 14.1502\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f7d0f7a84b4c89976b378461eb510b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\t loss: 13.3711\t val loss: 12.8383\t FID_25: 239.0325\t FID_50: 234.9365\n",
      "Saved checkpoint at epoch 4 with val loss 12.8383\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27280b8c676344898fade51029086897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\t loss: 12.1774\t val loss: 11.7377\t FID_25: 236.4914\t FID_50: 237.3486\n",
      "Saved checkpoint at epoch 5 with val loss 11.7377\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df25a878d5b34439ab1d2511e19e56dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\t loss: 11.2177\t val loss: 10.8918\t FID_25: 231.2109\t FID_50: 229.3739\n",
      "Saved checkpoint at epoch 6 with val loss 10.8918\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "038139d3ebcc4c319929f8bc514e8195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\t loss: 10.3140\t val loss: 9.9680\t FID_25: 230.3189\t FID_50: 236.2601\n",
      "Saved checkpoint at epoch 7 with val loss 9.9680\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950ca63afce947048fab9938f8106935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\t loss: 9.6016\t val loss: 9.3335\t FID_25: 230.4183\t FID_50: 231.6828\n",
      "Saved checkpoint at epoch 8 with val loss 9.3335\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13ce68997344e2fb0ec2a04a872703f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_history, val_loss_history = train(\n",
    "    model=model,\n",
    "    dataloader=train_dataloader,\n",
    "    val_dataloader=test_dataloader,\n",
    "    n_epochs=N_EPOCHS,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    verbose=True,\n",
    ")\n",
    "plt.plot(loss_history)\n",
    "plt.plot(val_loss_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
